% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/09_assistant_chat.R
\name{assistant_evaluate}
\alias{assistant_evaluate}
\title{Evaluate Assistant Answer}
\usage{
assistant_evaluate(question, answer, ground_truth_answer)
}
\arguments{
\item{question}{The original question that was asked}

\item{answer}{The answer to evaluate (from assistant or RAG system)}

\item{ground_truth_answer}{The correct/expected answer to compare against}
}
\value{
List with http response, content (evaluation metrics), and status_code.
  Content includes:
  - correctness: Precision of the answer (0 to 1)
  - completeness: Recall of the answer (0 to 1)
  - alignment: Harmonic mean of correctness and completeness
}
\description{
Evaluates the correctness and completeness of a response from an assistant
or RAG system by comparing it against a ground truth answer.
}
\details{
This endpoint evaluates answers based on:
- Correctness: How precise is the answer? (Are the facts stated correct?)
- Completeness: How complete is the answer? (Are all expected facts present?)
- Alignment: Combined score (harmonic mean of correctness and completeness)
}
\examples{
\dontrun{
# Evaluate an answer
assistant_evaluate(
  question = "What are the capital cities of France, England and Spain?",
  answer = "Paris is the capital of France and London is the capital of England.",
  ground_truth_answer = "Paris is the capital of France, London is the capital of England, and Madrid is the capital of Spain."
)
}
}
