% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/06_bulk_operations.R
\name{start_import}
\alias{start_import}
\title{Start Bulk Import}
\usage{
start_import(index, uri, integration_id = NULL, error_mode = "continue")
}
\arguments{
\item{index}{Name of the index to import into}

\item{uri}{The URI of the data to import. Supported formats:
- S3: "s3://bucket-name/path/to/data/"
- GCS: "gs://bucket-name/path/to/data/"}

\item{integration_id}{Optional ID of the storage integration to use for authentication}

\item{error_mode}{How to handle errors during import:
- "continue": Skip failed records and continue (default)
- "abort": Stop the import on first error}
}
\value{
List with http response, content (import operation details), and status_code.
  Content includes:
  - id: Unique identifier for the import operation
  - status: Current status (e.g., "Pending", "InProgress")
}
\description{
Starts an asynchronous import operation to load vectors from object storage
(S3 or GCS) into a Pinecone index.
}
\details{
The data files must be in Parquet format with the following schema:
- id (string): Unique vector ID
- values (list of floats): Vector values
- sparse_values (optional): Sparse vector data
- metadata (optional): Key-value metadata
}
\examples{
\dontrun{
# Import from S3
result <- start_import(
  index = "my-index",
  uri = "s3://my-bucket/vectors/"
)

# Check the import ID
import_id <- result$content$id

# Import with error handling
result <- start_import(
  index = "my-index",
  uri = "s3://my-bucket/vectors/",
  error_mode = "abort"
)
}
}
